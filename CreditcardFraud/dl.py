# -*- coding: utf-8 -*-
"""DL.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14NIMX55_-4pRw-nedv3Z6L52fQHQlv8w
"""

# EDA
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Load dataset
df = pd.read_csv('/content/creditcard.csv')

# Scale numerical features
scaler = StandardScaler()
df['scaled_amount'] = scaler.fit_transform(df[['Amount']])
df['scaled_time'] = scaler.fit_transform(df[['Time']])
df.drop(['Amount', 'Time'], axis=1, inplace=True)

# Split into features and target
X = df.drop('Class', axis=1).values
y = df['Class'].values

# Stratified split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

print(X_train.shape, X_test.shape)

# Supervised Classifier - ANN
import tensorflow as tf
from tensorflow.keras import layers, models
from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

model_dl = models.Sequential([
    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),
    layers.BatchNormalization(),
    layers.Dropout(0.3),
    layers.Dense(64, activation='relu'),
    layers.Dropout(0.3),
    layers.Dense(32, activation='relu'),
    layers.Dense(1, activation='sigmoid')
])

model_dl.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
    loss='binary_crossentropy',
    metrics=['Precision', 'Recall', 'AUC']
)

history = model_dl.fit(
    X_train, y_train,
    validation_data=(X_test, y_test),
    epochs=50, batch_size=128,
    class_weight={0:1, 1:10},  # handle imbalance
    verbose=1
)

# Predictions
y_pred_prob = model_dl.predict(X_test)
y_pred = (y_pred_prob > 0.5).astype(int)

# Metrics
print("ROC-AUC:", roc_auc_score(y_test, y_pred_prob))
print(classification_report(y_test, y_pred))

# Confusion Matrix
plt.figure(figsize=(5,4))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')
plt.title("DL Model - Confusion Matrix")
plt.show()

# Learning Curves
plt.plot(history.history['AUC'], label='Train AUC')
plt.plot(history.history['val_AUC'], label='Val AUC')
plt.title("Training vs Validation AUC")
plt.legend()
plt.show()

# ROC curve
from sklearn.metrics import roc_curve
fpr, tpr, _ = roc_curve(y_test, y_pred_prob)
plt.figure(figsize=(5,4))
plt.plot(fpr, tpr, label=f"AUC = {roc_auc_score(y_test, y_pred_prob):.3f}")
plt.plot([0,1],[0,1],'--',color='gray')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.title("ROC Curve - Deep Learning Model")
plt.show()

model_dl.save("fraud_detection_dl_model.h5")

# Autoencoder (Unsupervised)
from tensorflow.keras import Model, Input

input_dim = X_train.shape[1]
encoding_dim = 16  # compressed latent space

input_layer = Input(shape=(input_dim,))
encoded = layers.Dense(encoding_dim, activation='relu')(input_layer)
decoded = layers.Dense(input_dim, activation='sigmoid')(encoded)

autoencoder = Model(inputs=input_layer, outputs=decoded)
autoencoder.compile(optimizer='adam', loss='mse')

autoencoder.fit(
    X_train[y_train == 0], X_train[y_train == 0],
    epochs=40, batch_size=32, validation_split=0.1, verbose=1
)

encoder = Model(inputs=input_layer, outputs=encoded)
X_train_latent = encoder.predict(X_train)
X_test_latent = encoder.predict(X_test)
print("Latent space shape:", X_train_latent.shape)

!pip -q install optuna xgboost

# Hybrid Model with Optuna, XGBoost
import optuna
import xgboost as xgb
from sklearn.metrics import roc_auc_score
from sklearn.model_selection import StratifiedKFold
import numpy as np

def objective(trial):
    params = {
        "objective": "binary:logistic",
        "eval_metric": "auc",
        "tree_method": "hist",         # or 'gpu_hist' if you have GPU
        "learning_rate": trial.suggest_float("learning_rate", 0.01, 0.3, log=True),
        "max_depth": trial.suggest_int("max_depth", 3, 10),
        "min_child_weight": trial.suggest_float("min_child_weight", 1, 20),
        "subsample": trial.suggest_float("subsample", 0.5, 1.0),
        "colsample_bytree": trial.suggest_float("colsample_bytree", 0.5, 1.0),
        "gamma": trial.suggest_float("gamma", 0, 5),
        "reg_alpha": trial.suggest_float("reg_alpha", 1e-8, 1e-1, log=True),
        "reg_lambda": trial.suggest_float("reg_lambda", 1e-8, 1, log=True),
        "scale_pos_weight": (y_train==0).sum() / max(1, (y_train==1).sum()),
        "n_estimators": trial.suggest_int("n_estimators", 200, 800),
    }

    # 3-fold Stratified CV
    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)
    aucs = []

    for tr_idx, val_idx in skf.split(X_train, y_train):
        X_tr, X_val = X_train[tr_idx], X_train[val_idx]
        y_tr, y_val = y_train[tr_idx], y_train[val_idx]

        model = xgb.XGBClassifier(**params, n_jobs=-1)
        model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], verbose=False)
        preds = model.predict_proba(X_val)[:, 1]
        aucs.append(roc_auc_score(y_val, preds))

    return np.mean(aucs)

study = optuna.create_study(direction="maximize")
study.optimize(objective, n_trials=20, show_progress_bar=True)

best_params = study.best_params
best_params.update({
    "objective": "binary:logistic",
    "eval_metric": "auc",
    "tree_method": "hist",
    "n_jobs": -1,
    "random_state": 42
})

print("Best Parameters:", best_params)

model_xgb = xgb.XGBClassifier(**best_params)
model_xgb.fit(X_train, y_train)

y_pred_prob = model_xgb.predict_proba(X_test)[:, 1]
y_pred = (y_pred_prob > 0.5).astype(int)

print("Optuna-XGBoost ROC-AUC:", roc_auc_score(y_test, y_pred_prob))

import pandas as pd

results = pd.DataFrame({
    'Model': ['Deep Neural Network', 'Autoencoder + XGBoost'],
    'ROC-AUC': [
        roc_auc_score(y_test, y_pred_prob),
        roc_auc_score(y_test, y_pred_prob_xgb)
    ]
})

display(results)

import joblib
import tensorflow as tf

# Save models
encoder.save("fraud_autoencoder.h5")
joblib.dump(model_xgb, "fraud_xgb.pkl")

# Create a metadata bundle
bundle = {
    "autoencoder_path": "fraud_autoencoder.h5",
    "xgb_model_path": "fraud_xgb.pkl"
}

# Save the bundle
joblib.dump(bundle, "fraud_hybrid_model.pkl")
print("Autoencoder, XGBoost, and bundle saved successfully!")